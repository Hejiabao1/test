import os
import pandas as pd
import torch
import numpy as np
from dataset import BME, MyDataset, dataset_split
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
from model.CNN_LSTM import Net # ç¡®ä¿è¿™æŒ‡å‘æ­£ç¡®çš„SleepNetå®šä¹‰æ–‡ä»¶
import streamlit as st
import time
import base64
import matplotlib as plt


def binary_accuracy(preds, y):
    """
    è®¡ç®—äºŒåˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚
    """
    rounded_preds = torch.round(torch.sigmoid(preds))#é¦–å…ˆå°†é¢„æµ‹å€¼åº”ç”¨ sigmoid å‡½æ•°ï¼Œç„¶åå¯¹ç»“æœè¿›è¡Œå››èˆäº”å…¥ã€‚
    correct = (rounded_preds == y).float()#å°†å››èˆäº”å…¥åçš„é¢„æµ‹å€¼ä¸çœŸå®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œå¾—åˆ°ä¸€ä¸ªå¸ƒå°”å¼ é‡ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹å¼ é‡ã€‚
    acc = correct.sum() / len(correct)#è®¡ç®—å‡†ç¡®é¢„æµ‹çš„æ•°é‡å¹¶é™¤ä»¥æ€»æ ·æœ¬æ•°é‡ï¼Œå¾—åˆ°å‡†ç¡®ç‡ã€‚
    return acc.item()#è¿”å›å‡†ç¡®ç‡çš„æ•°å€¼éƒ¨åˆ†

# def classify_and_count(predictions):
#     """
#     å¯¹æ¨¡å‹è¾“å‡ºçš„logitsè¿›è¡ŒäºŒåˆ†ç±»ï¼Œå¹¶ç»Ÿè®¡0å’Œ1çš„æ•°é‡ã€‚
#     """
#     # å‡è®¾æ‚¨ä½¿ç”¨0.5ä½œä¸ºé˜ˆå€¼è¿›è¡Œåˆ†ç±»
#     binary_predictions = (predictions > 0.5).astype(int)
#     # ç¡®ä¿binary_predictionsæ˜¯ä¸€ç»´çš„ä¸”å…ƒç´ ä¸ºéè´Ÿæ•´æ•°
#     if binary_predictions.ndim > 1:
#         binary_predictions = binary_predictions.flatten()
#
#     # ç¡®ä¿æ‰€æœ‰å…ƒç´ ä¸ºéè´Ÿæ•´æ•°
#     binary_predictions = np.where(binary_predictions >= 0, binary_predictions, 0).astype(int)
#     counts = np.bincount(binary_predictions)
#
#     if counts[0] >= counts[1]:  # å¦‚æœ0çš„æ•°é‡å¤§äºç­‰äº1çš„æ•°é‡
#         return 0
#     else:
#         return 1
def classify_and_count(predictions):
    """
    å¯¹æ¨¡å‹è¾“å‡ºçš„logitsè¿›è¡ŒäºŒåˆ†ç±»ï¼Œå¹¶ç»Ÿè®¡0å’Œ1çš„æ•°é‡ã€‚
    """
    # å‡è®¾æ‚¨ä½¿ç”¨0.5ä½œä¸ºé˜ˆå€¼è¿›è¡Œåˆ†ç±»
    binary_predictions = (predictions > 0.5).astype(int)
    # ç¡®ä¿binary_predictionsæ˜¯ä¸€ç»´çš„ä¸”å…ƒç´ ä¸ºéè´Ÿæ•´æ•°
    if binary_predictions.ndim > 1:
        binary_predictions = binary_predictions.flatten()

    # ç¡®ä¿æ‰€æœ‰å…ƒç´ ä¸ºéè´Ÿæ•´æ•°ï¼Œè¿™ä¸€æ­¥åœ¨è½¬æ¢ä¸ºintåå…¶å®å·²ç»ä¿è¯äº†éè´Ÿï¼Œå¯ä»¥è€ƒè™‘å»æ‰
    binary_predictions = np.where(binary_predictions >= 0, binary_predictions, 0).astype(int)

    counts = np.bincount(binary_predictions)

    # æ£€æŸ¥countsé•¿åº¦ï¼Œå¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ«
    if len(counts) == 1:
        # ç›´æ¥è¿”å›è¯¥ç±»åˆ«ï¼Œå› ä¸ºbinary_predictionsä¸­åªæœ‰ä¸€ç§å€¼ï¼Œæˆ‘ä»¬ç›´æ¥å–å…¶å€¼å³å¯
        unique_value = np.unique(binary_predictions)[0]
        return unique_value

    # å¦‚æœæœ‰ä¸¤ç±»ï¼Œåˆ™æŒ‰åŸé€»è¾‘åˆ¤æ–­
    if counts[0] >= counts[1]:
        return 0
    else:
        return 1

def validate(model, dataloader, criterion, device):
    model.eval()
    running_loss = 0.0
    running_corrects = 0

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels.unsqueeze(1).float())

            running_loss += loss.item() * inputs.size(0)
            running_corrects += binary_accuracy(outputs, labels.unsqueeze(1).float()) * inputs.size(0)

            outputs = torch.round(torch.sigmoid(outputs)).detach().cpu().numpy()
            labels = labels.detach().cpu().numpy()
            # å°†é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾æ·»åŠ åˆ°åˆ—è¡¨ä¸­

    epoch_loss = running_loss / len(dataloader.dataset)
    epoch_acc = running_corrects / len(dataloader.dataset)

    from sklearn.metrics import confusion_matrix, f1_score
    cm = confusion_matrix(labels, outputs)
    TP = cm[0, 0]
    FN = cm[0, 1]
    FP = cm[1, 0]
    TN = cm[1, 1]

    # è®¡ç®—æ•æ„Ÿæ€§ï¼ˆSeï¼‰å’Œç‰¹å¼‚æ€§ï¼ˆSpï¼‰
    Se = TP / (TP + FN)
    Sp = TN / (TN + FP)

    # è®¡ç®— F1 åˆ†æ•°
    F1 = f1_score(labels, outputs)

    print(f"æ··æ·†çŸ©é˜µ:\n{cm}")
    print(f"æ•æ„Ÿæ€§: {Se}")
    print(f"ç‰¹å¼‚æ€§: {Sp}")
    print(f"F1 åˆ†æ•°: {F1}")

    print(f'test Average loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}')
    return epoch_loss, epoch_acc,Se,Sp,F1

def save_results_to_csv(predictions, filename='predict_results_3.csv', mode='a'):
    """
    å°†æµ‹è¯•ç»“æœä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­ï¼Œå¦‚æœæ–‡ä»¶å­˜åœ¨åˆ™è¿½åŠ ã€‚
    """
    # ç”Ÿæˆåºå·åˆ—è¡¨ï¼Œä»1å¼€å§‹ï¼Œé•¿åº¦ä¸predictionsç›¸åŒ
    ids = list(range(1, len(predictions) + 1))
    # åˆ›å»ºä¸€ä¸ªDataFrameï¼ŒåŒ…å«IDå’ŒResultsä¸¤åˆ—
    df = pd.DataFrame({'ID': ids, 'Results': predictions})
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
    if not os.path.exists(filename):
        df.to_csv(filename, index=False, mode='w')
    else:
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œåˆ™ä»¥è¿½åŠ æ¨¡å¼å†™å…¥
        df.to_csv(filename, index=False, header=False, mode=mode)


def test_my_net(patient_index,network):
    # å®ä¾‹åŒ–æ¨¡å‹
    hidden_size = 32
    seq_len = 750
    is_bidirectional = True
    network = "LSTM"  # æˆ–å…¶ä»–æ‚¨åœ¨è®­ç»ƒæ—¶ä½¿ç”¨çš„ç½‘ç»œç±»å‹
    model = Net(hidden_size, seq_len, is_bidirectional, network)

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼

    # ç¤ºä¾‹ï¼šåˆ›å»ºå‡æ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®æµ‹è¯•é›†
    # åŠ è½½æ•°æ®é›†
    bme = BME(time_len=3, time_step=2)
    bme.processing()
    # train_val_dataset = bme.load()
    # trainset, restset = dataset_split(train_val_dataset, val_rate=0.4)
    # valset, testset = dataset_split(restset, val_rate=0.25)
    testset = bme.load_test_data

    # å‡è®¾æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªbatchçš„æµ‹è¯•æ•°æ®ï¼Œå½¢çŠ¶åº”ç¬¦åˆæ¨¡å‹è¾“å…¥è¦æ±‚
    batchsize = 32  # é€‰æ‹©ä¸€ä¸ªé€‚åˆæµ‹è¯•çš„batch size
    # å¤„ç†æ•°æ®é›†éƒ¨åˆ†ï¼Œå®ä¾‹åŒ–æ•°æ®é›†ï¼Œæ„å»ºDataLoader
    # train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)  # [1, 2, 750]
    # val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)
    # test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)
    # test_data_indices = list(range(0, 15))  # ç¤ºä¾‹ï¼šä½¿ç”¨å‰15ä¸ªæ•°æ®ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    test_data_indices = [patient_index]
    test_samples = bme.load_test_data(sub_index=test_data_indices)  # è°ƒç”¨æ–¹æ³•å¹¶ä¼ å…¥ç´¢å¼•èŒƒå›´
    # testset = torch.utils.data.TensorDataset(torch.tensor(test_samples), torch.zeros(len(test_samples)))  # å‡è®¾æ ‡ç­¾å…¨ä¸º0ï¼Œä»…ä½œç¤ºä¾‹
    testset = torch.utils.data.TensorDataset(test_samples.clone().detach(),
                                             torch.zeros(len(test_samples), dtype=torch.float32).detach())
    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)
    # é€šè¿‡æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¿™æ¬¡ä½¿ç”¨çœŸå®çš„æµ‹è¯•æ•°æ®
    all_predictions = []
    with torch.no_grad():
        for data in test_loader:
            inputs, _ = data
            inputs = inputs.to(device)
            outputs = model(inputs)
            probabilities = torch.sigmoid(outputs)  # ä½¿ç”¨sigmoidå°†logitsè½¬åŒ–ä¸ºæ¦‚ç‡
            # å‡è®¾ probabilities æ˜¯ä¸€ä¸ªåŒ…å«æ¦‚ç‡çš„å¼ é‡ï¼Œå¯¹äºäºŒåˆ†ç±»é—®é¢˜
            rounded_probs = torch.round(probabilities)  # å››èˆäº”å…¥æ¦‚ç‡å€¼
            predicted_classes = rounded_probs.detach().cpu().numpy().astype(int)  # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ç¡®ä¿æ˜¯æ•´æ•°ç±»å‹

            all_predictions.extend(predicted_classes)

    final_prediction = classify_and_count(np.array(all_predictions))
    st.write(f"æœ€ç»ˆé¢„æµ‹æ ·æœ¬çš„æ ‡ç­¾ä¸º: {final_prediction}")
    if final_prediction == 0:
        st.markdown(f'<span style="color:#8B0000; font-weight:bold; font-size:24px;">æ‚¨çš„çŠ¶æ€ä¸å¤ªå¥½ï¼Œè¦å¥½å¥½å¯¹å¾…è‡ªå·±å™¢ğŸ˜¡</span>',
                    unsafe_allow_html=True)
    else:
        st.markdown(f'<span style="color:green; font-weight:bold; font-size:24px;">æ‚¨çš„èº«ä½“å¾ˆå¥åº·ï¼Œè¯·ç»§ç»­ä¿æŒè‰¯å¥½çš„çŠ¶æ€å™¢ğŸ˜¯</span>', unsafe_allow_html=True)
    print(f"Final Prediction (Based on Counts): {final_prediction}")
    # ä¿å­˜é¢„æµ‹ç»“æœåˆ°CSV
    save_results_to_csv([final_prediction])
    # _, _, Se, Sp, F1 = validate(model, test_loader, criterion=criterion, device=device)
    # print(f"Test Accuracy (Based on Validation): Not Directly Computed Here")  # æ³¨æ„ï¼šè¿™é‡Œçš„å‡†ç¡®ç‡éœ€æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´è®¡ç®—æ–¹å¼
    # print(f"Specificity: {Sp}")
    # print(f"Sensitivity: {Se}")
    # print(f"F1 Score: {F1}")



if __name__ == '__main__':
    # å‡è®¾æ‚¨å·²ç»ä¿å­˜äº†æ¨¡å‹æƒé‡åˆ°æŸä¸ªè·¯å¾„ï¼Œä¾‹å¦‚'model.pth'
    model_path = r'D:\Pytharm\py_Project\Depression_Detect_new\Depression_Detect\EEG_Depression\all_best_model.pth'
    criterion = torch.nn.BCEWithLogitsLoss()
    # model = SleepNet(hidden_size=32, seq_len=750, is_bidirectional=True, network="LSTM")
    # è®¾ç½®æµ‹è¯•æ—¶ä½¿ç”¨çš„è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


    @st.cache_data
    def get_base64_of_bin_file(bin_file):
        with open(bin_file, "rb") as f:
            data = f.read()
        return base64.b64encode(data).decode()


    def page_bg(jpg_file):
        """è®¾ç½®ç½‘é¡µèƒŒæ™¯å›¾ç‰‡"""
        bin_str = get_base64_of_bin_file(jpg_file)
        page_bg_css = f"""
           <style>
           .stApp {{
               background-image: url("data:image/jpeg;base64,{bin_str}");
               background-size: 100% 120%;
               background-repeat: no-repeat;
               background-attachment: center;
           }}
           </style>
           """

        st.markdown(page_bg_css, unsafe_allow_html=True)


    # è®¾ç½®èƒŒæ™¯å›¾ç‰‡
    page_bg(r"D:\Pytharm\py_Project\Depression_Detect_new\Depression_Detect\EEG_Depression\yiyuzheng.jpg")
    # åŠ è½½å›¾ç‰‡
    # å›¾ç‰‡è½¬Base64ç¼–ç å‡½æ•°
    def get_image_base64(image_filename):
        with open(image_filename, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode()
        return encoded_string


    image_filename = "logo.png"  # å›¾ç‰‡æ–‡ä»¶å
    image_base64 = get_image_base64(image_filename)
    img_tag = f'<img src="data:image/png;base64,{image_base64}" alt="ä¾§è¾¹æ å›¾ç‰‡" style="width: 100%; max-width: 200px; display: block; margin: auto;">'
    # è®¾ç½®ä¸¤åˆ—å¸ƒå±€ï¼Œç¬¬ä¸€åˆ—å®½åº¦è®¾ä¸ºå›¾ç‰‡åˆé€‚çš„æ¯”ä¾‹ï¼Œç¬¬äºŒåˆ—è‡ªåŠ¨å¡«å……å‰©ä½™ç©ºé—´
    col1, col2 = st.columns([2,9])  # 3 å’Œ 2 æ˜¯åˆ—çš„æ¯”ä¾‹ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´

    with col1:  # åœ¨ç¬¬ä¸€åˆ—æ˜¾ç¤ºå›¾ç‰‡
        st.markdown(img_tag, unsafe_allow_html=True)

    with col2:  # åœ¨ç¬¬äºŒåˆ—æ˜¾ç¤ºæ ‡é¢˜
        st.title("é’å°‘å¹´æŠ‘éƒç—‡æ£€æµ‹é¢„é˜²ç³»ç»Ÿ")
        st.markdown(f'''
                <div style="padding-left: 20px;">
                    <span style="color:black; font-weight:bold; font-style:italic; font-size:24px;">------æ¬¢è¿æ¥åˆ°â€œå¿ƒå¢ƒå®ˆæŠ¤ï¼ŒæŠ‘éƒæ™ºæ£€â€é’å°‘å¹´æŠ‘éƒæ£€æµ‹å¹³å°ğŸ‘ğŸ‘</span>
                </div>
                ''', unsafe_allow_html=True)

    st.sidebar.title("ğŸ å¿ƒå¢ƒå®ˆæŠ¤ï¼ŒæŠ‘éƒæ™ºæ£€")

    # åˆ†éš”çº¿å¢å¼ºè§†è§‰åŒºåˆ†
    st.sidebar.markdown("---")



    st.sidebar.markdown(img_tag, unsafe_allow_html=True)
    st.sidebar.header("å‚æ•°é€‰æ‹©ï¼š")
    # åœ¨è¿™é‡Œæ·»åŠ ä¾§è¾¹æ çš„å†…å®¹ï¼Œä¾‹å¦‚ï¼š
    selected_option = st.sidebar.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹", ["é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆCNN-LSTMï¼‰", "CNN-GRU"])
    sex = st.sidebar.radio(
        label='è¯·é€‰æ‹©ä½ çš„é€šé“æ•°',
        options=('å•é€šé“', 'åŒé€šé“','ä¸‰é€šé“'),
        index=0,
        format_func=str,
        help='é€‰æ‹©å¿ƒç”µï¼Œè„‘ç”µï¼Œå¿ƒè„‘ç”µå¯¹åº”é€‰æ‹©å•é€šé“ï¼ŒåŒé€šé“å’Œä¸‰é€šé“'
    )
    cb = st.sidebar.checkbox('æ˜¯å¦é€‰æ‹©åŒå‘ï¼ˆé»˜è®¤ä¸ºå¦ï¼‰', value=False)
    selected_option2 = st.sidebar.selectbox("è¯·é€‰æ‹©æµ‹é‡æ¨¡æ€", ["è„‘ç”µå•æ¨¡æ€", "å¿ƒç”µå•æ¨¡æ€", "å¿ƒè„‘ç”µåŒæ¨¡æ€"])


    # åˆ†éš”çº¿å¢å¼ºè§†è§‰åŒºåˆ†
    st.markdown("---")

    st.header("å‚æ•°é¢„è§ˆï¼ˆé€šè¿‡å·¦è¾¹ä¾§è¾¹æ çš„é€‰é¡¹è¿›è¡Œæ›´æ”¹ï¼‰")

    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_style = """
    <style>
    .font-style {
        font-family: Arial, sans-serif; /* æ›´æ”¹å­—ä½“ */
        font-size: 30px; /* æ›´æ”¹å­—ä½“å¤§å° */
        color: #000000; /* æ›´æ”¹å­—ä½“é¢œè‰² */
    }
    </style>
    """

    # åº”ç”¨è‡ªå®šä¹‰æ ·å¼
    st.markdown(custom_style, unsafe_allow_html=True)




    if selected_option == "é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆCNN-LSTMï¼‰":
        selected_network = "LSTM"
        st.markdown("<p class='font-style'>1ï¸âƒ£å½“å‰æ¨¡å‹ä¸ºï¼š<strong>CNN-LSTM</strong></p>", unsafe_allow_html=True)
    elif selected_option == "CNN-GRU":
        selected_network = "GRU"
        st.markdown("<p class='font-style'>1ï¸âƒ£å½“å‰æ¨¡å‹ä¸ºï¼š<strong>CNN-GRU</strong></p>", unsafe_allow_html=True)
    else:
        st.error("ERROR")

    if sex == 'å•é€šé“':
        st.markdown("<p class='font-style'>2ï¸âƒ£å½“å‰é€šé“ä¸ºï¼š<strong>å•é€šé“</strong></p>", unsafe_allow_html=True)
    elif sex == 'åŒé€šé“':
        st.markdown("<p class='font-style'>2ï¸âƒ£å½“å‰é€šé“ä¸ºï¼š<strong>åŒé€šé“</strong></p>", unsafe_allow_html=True)
    else:
        st.markdown("<p class='font-style'>2ï¸âƒ£å½“å‰é€šé“ä¸ºï¼š<strong>ä¸‰é€šé“</strong></p>", unsafe_allow_html=True)

    if cb:
        st.markdown("<p class='font-style'>3ï¸âƒ£åŒå‘é€‰æ‹©ï¼š<strong>æ˜¯</strong></p>", unsafe_allow_html=True)
    else:
        st.markdown("<p class='font-style'>3ï¸âƒ£åŒå‘é€‰æ‹©ï¼š<strong>å¦</strong></p>", unsafe_allow_html=True)

    if selected_option2 == "è„‘ç”µå•æ¨¡æ€":
        selected_network = "è„‘ç”µå•æ¨¡æ€"
        st.markdown("<p class='font-style'>4ï¸âƒ£å½“å‰æ¨¡æ€ä¸ºï¼š<strong>è„‘ç”µå•æ¨¡æ€</strong></p>", unsafe_allow_html=True)
    elif selected_option2 == "å¿ƒç”µå•æ¨¡æ€":
        selected_network = "å¿ƒç”µå•æ¨¡æ€"
        st.markdown("<p class='font-style'>4ï¸âƒ£å½“å‰æ¨¡æ€ä¸ºï¼š<strong>å¿ƒç”µå•æ¨¡æ€ï¸</strong></p>", unsafe_allow_html=True)
    else:
        st.markdown("<p class='font-style'>4ï¸âƒ£å½“å‰æ¨¡æ€ä¸ºï¼š<strong>å¿ƒè„‘ç”µåŒæ¨¡æ€ï¸</strong></p>", unsafe_allow_html=True)

    # åˆ†éš”çº¿å¢å¼ºè§†è§‰åŒºåˆ†
    st.markdown("---")

    st.header("æ£€æµ‹åŒºåŸŸï¼ˆæ³¨ï¼šè¯·é€‰æ‹©æ­£ç¡®çš„æ–‡ä»¶æ ¼å¼ï¼‰")
    col1, col2 = st.columns(2)  # ä½¿ç”¨åˆ—å¸ƒå±€è¿›è¡Œè°ƒæ•´
    # æ–‡ä»¶ä¸Šä¼ ä¸æ£€æµ‹åŒºåŸŸ

    # å¿ƒç”µæ–‡ä»¶ä¸Šä¼ 
    ecg_uploaded_file = None
    with col1:
        uploaded_file1 = st.file_uploader("ä¸Šä¼ å¿ƒç”µæ–‡ä»¶", type=["csv"])
        if uploaded_file1 is not None:
            if uploaded_file1.name != "ecgsignals.csv":
                st.warning("è¯·ä¸Šä¼ æ­£ç¡®æ ¼å¼çš„å¿ƒç”µæ–‡ä»¶ã€‚")
            else:
                ecg_uploaded_file = uploaded_file1



    # è„‘ç”µæ–‡ä»¶ä¸Šä¼ 
    eeg_uploaded_file = None
    with col2:
        uploaded_file2 = st.file_uploader("ä¸Šä¼ è„‘ç”µæ–‡ä»¶", type=["csv"])
        if uploaded_file2 is not None:
            if uploaded_file2.name != "eegsignals.csv":
                st.warning("è¯·ä¸Šä¼ æ­£ç¡®æ ¼å¼çš„è„‘ç”µæ–‡ä»¶ã€‚")
            else:
                eeg_uploaded_file = uploaded_file2



    patient_index_input = st.number_input("è¾“å…¥æ‚£è€…ç¼–å·", min_value=0, max_value=14, value=0)  # æ–°å¢è¾“å…¥æ¡†
    patient_index_input = int(patient_index_input)
    detect_button = st.button("ç‚¹å‡»æ£€æµ‹")

    import matplotlib.pyplot as plt




    # åˆ†éš”çº¿å¢å¼ºè§†è§‰åŒºåˆ†
    st.markdown("---")
    # ç»“æœå±•ç¤ºåŒºåŸŸ
    st.header("âŒ›ï¸æ£€æµ‹ç»“æœ")


    result_placeholder = st.empty()
    progress_bar = st.empty()


    def show_progress():
        """æ¨¡æ‹Ÿè¿›åº¦æ¡åŠ¨ç”»"""

        for i in range(21):
            progress_bar.progress(i / 20, 'è¿›åº¦')
            time.sleep(0.5)

        with st.spinner('åŠ è½½ä¸­...'):
            time.sleep(5)


    if detect_button and uploaded_file1 is not None and uploaded_file2 is not None:
        result_placeholder.empty()
        progress_bar.progress(0)
        try:
            show_progress()
            test_my_net(patient_index_input,selected_network)
            # å‡è®¾test_sleep_netæ˜¯å¤„ç†ä¸Šä¼ æ–‡ä»¶å¹¶è¿”å›ç»“æœçš„å‡½æ•°ï¼Œéœ€ç¡®ä¿è¯¥å‡½æ•°å·²å®šä¹‰
            result_placeholder.success(f"æ“ä½œæˆåŠŸï¼Œç»“æœå¦‚ä¸‹ã€‚\n\n")
            # æ·»åŠ è¶…é“¾æ¥
            link_text = "[<p class='font-style'>â€”>æ›´å¤šé¢„é˜²é’å°‘å¹´æŠ‘éƒç—‡çš„çŸ¥è¯†ï¼Œç‚¹å‡»æ­¤å¤„å‰å¾€<â€”</p>](https://xueshu.baidu.com/s?wd=%E9%9D%92%E5%B0%91%E5%B9%B4%E6%8A%91%E9%83%81%E7%97%87%E9%A2%84%E9%98%B2&tn=SE_baiduxueshu_c1gjeupa&ie=utf-8&sc_hit=1)"  # è¯·å°†https://www.example.com/depression-preventionæ›¿æ¢ä¸ºå®é™…é“¾æ¥
            st.markdown(link_text, unsafe_allow_html=True)
        except Exception as e:
            result_placeholder.error(f"æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    else:
        st.info("è¯·ç¡®ä¿æˆåŠŸä¸Šä¼ æ–‡ä»¶å¹¶é€‰æ‹©æ‚£è€…ç¼–å·åç‚¹å‡»æŒ‰é’®è¿›è¡Œæ£€æµ‹ã€‚")
